# Задание 1:

## Предлагаемое решение

Для обеспечения процесса разработки микросервисной архитектуры предлагаю использовать GitLab как единую платформу, включающую:

- **GitLab.com** — облачная платформа для хранения кода
- **GitLab CI/CD** — система непрерывной интеграции и доставки
- **GitLab Runner** — агенты для выполнения сборок (облачные и на собственных серверах)
- **GitLab Container Registry** — встроенное хранилище Docker образов

---

## Архитектура решения

Решение построено по следующему принципу:

### Уровень 1: Хранение кода

- GitLab.com хранит исходный код всех микросервисов
- Каждый микросервис находится в отдельном Git-репозитории
- Используется стандартный Git workflow с ветками и merge requests

### Уровень 2: Автоматизация сборки

- При изменении кода (git push) автоматически запускается pipeline
- Pipeline описывается в файле конфигурации, который лежит в каждом репозитории
- Система автоматически выполняет все необходимые шаги: сборку, тестирование, упаковку в Docker

### Уровень 3: Выполнение задач

- Задачи выполняют GitLab Runners — специальные агенты
- Runners могут быть облачными (предоставляет GitLab) или развёрнуты на собственных серверах
- Runners забирают задачи из очереди и выполняют их в изолированных Docker-контейнерах

### Уровень 4: Хранение результатов

- Собранные Docker-образы сохраняются в GitLab Container Registry
- Оттуда они могут быть развёрнуты в production-окружение

---

## Соответствие требованиям и обоснование

### 1. Облачная система

**Решение:** GitLab.com — полностью облачная SaaS-платформа.  
**Обоснование:**

- Не требует установки и поддержки собственной инфраструктуры — начать работу можно за 5 минут
- Автоматические обновления и исправления безопасности выполняются GitLab без участия команды
- Высокая доступность обеспечивается самим GitLab (гарантия uptime 99.95%)
- Масштабирование происходит автоматически — не нужно беспокоиться о мощности серверов

### 2. Система контроля версий Git

**Решение:** GitLab имеет встроенную Git-систему с полной поддержкой всех Git-функций.  
**Обоснование:**

- Нативная интеграция Git с CI/CD — не нужны дополнительные плагины или настройки
- Веб-интерфейс для просмотра кода, истории изменений, сравнения версий
- Встроенные инструменты для code review через merge requests
- Поддержка защищённых веток, правил именования, hooks

### 3. Репозиторий на каждый сервис

**Решение:** В GitLab создаётся отдельный проект для каждого микросервиса.  
**Обоснование:**

- Независимая разработка — каждая команда работает со своим репозиторием без конфликтов
- Гибкие права доступа — можно дать команде доступ только к их сервисам
- Независимое версионирование — каждый сервис имеет свою историю релизов
- Упрощённое управление — изменения в одном сервисе не влияют на другие
- GitLab поддерживает группировку проектов через Groups для удобной организации

### 4. Запуск сборки по событию из системы контроля версий

**Решение:** GitLab CI/CD автоматически запускает pipeline при любых изменениях в Git.  
**Обоснование:**

- При каждом push автоматически запускается сборка — разработчику не нужно делать ничего дополнительно
- Можно настроить разные действия для разных веток — например, только для main ветки деплоить в production
- Поддержка trigger для merge requests — тестирование кода до его слияния с основной веткой
- Интеграция через webhooks происходит автоматически — не требуется ручная настройка

### 5. Запуск сборки по кнопке с указанием параметров

**Решение:** GitLab предоставляет возможность ручного запуска pipeline через веб-интерфейс.  
**Обоснование:**

- Кнопка "Run pipeline" доступна в один клик из веб-интерфейса
- Можно выбрать любую ветку или тег для сборки
- При запуске можно задать или переопределить переменные окружения
- Полезно для деплоя в production с подтверждением или для пересборки старых версий
- Есть возможность создавать manual jobs, которые требуют явного подтверждения перед выполнением

### 6. Возможность привязать настройки к каждой сборке

**Решение:** В GitLab используется система CI/CD Variables на разных уровнях.  
**Обоснование:**

- Переменные можно задать на уровне проекта — применяются ко всем сборкам этого сервиса
- Переменные на уровне группы — общие настройки для нескольких связанных сервисов
- Переменные на уровне конкретного запуска pipeline — для специфичных случаев
- Переменные могут быть разными для разных окружений (dev, staging, production)
- Поддержка переопределения переменных при ручном запуске

### 7. Возможность создания шаблонов для различных конфигураций сборок

**Решение:** GitLab поддерживает множественные механизмы переиспользования конфигураций.  
**Обоснование:**

- Механизм Include позволяет подключать общие конфигурации из отдельного репозитория шаблонов
- Механизм Extends позволяет наследовать настройки от базовых конфигураций
- YAML anchors для переиспользования блоков конфигурации внутри одного файла
- Можно создать репозиторий с шаблонами для типовых задач (сборка Node.js, Python, Go)
- Каждый микросервис подключает нужный шаблон и добавляет только специфичные настройки
- Изменение шаблона автоматически применяется ко всем сервисам, которые его используют

### 8. Возможность безопасного хранения секретных данных

**Решение:** GitLab CI/CD Variables с функциями защиты и шифрования.  
**Обоснование:**

- Все переменные хранятся в зашифрованном виде в базе данных GitLab
- Masked переменные — их значения автоматически скрываются во всех логах сборки
- Protected переменные — доступны только для защищённых веток (например, main или production)
- Разграничение прав доступа — не все разработчики могут видеть значения секретов
- Интеграция с внешними системами управления секретами (HashiCorp Vault, AWS Secrets Manager)
- Аудит использования — можно отследить, когда и кем использовались секреты

### 9. Несколько конфигураций для сборки из одного репозитория

**Решение:** GitLab позволяет описать множество различных сценариев сборки в одном файле конфигурации.  
**Обоснование:**

- Можно создать разные jobs для разных целей — сборка для development, staging, production
- Поддержка условного выполнения — job запускается только при определённых условиях
- Matrix builds — автоматическое создание множества вариантов сборки
- Можно собрать из одного кода версии для разных платформ (Linux, Windows, ARM)
- Разные наборы тестов для разных окружений
- Гибкая настройка через правила (rules) — какой job когда запускать

### 10. Кастомные шаги при сборке

**Решение:** GitLab предоставляет полную свободу в определении шагов сборки.  
**Обоснование:**

- В секции script можно написать любые команды shell
- Можно использовать любые инструменты и утилиты
- Поддержка before_script и after_script
- Возможность запускать внешние скрипты
- Интеграция сторонних инструментов
- Разбиение на стадии (stages)
- Поддержка артефактов

### 11. Собственные Docker-образы для сборки проектов

**Решение:** В GitLab можно указать любой Docker-образ для выполнения сборки.  
**Обоснование:**

- Полная свобода выбора
- Хранение образов в GitLab Container Registry
- Ускорение сборки
- Контроль версий инструментов
- Воспроизводимость окружения
- Разные образы для разных jobs
- Экономия времени

### 12. Возможность развернуть агентов сборки на собственных серверах

**Решение:** GitLab Runner можно установить на любую инфраструктуру.  
**Обоснование:**

- Self-hosted runners на VM, bare metal, Kubernetes
- Доступ к внутренним ресурсам
- Использование GPU и мощных серверов
- Compliance требования
- Экономия средств
- Полный контроль над окружением
- Гибридный подход

### 13. Возможность параллельного запуска нескольких сборок

**Решение:** GitLab поддерживает параллельное выполнение множества задач.  
**Обоснование:**

- Параллельные jobs в одной стадии
- Параллельные pipeline микросервисов
- Настройка количества одновременных задач
- Существенное ускорение CI/CD
- Эффективное использование ресурсов

### 14. Возможность параллельного запуска тестов

**Решение:** GitLab имеет встроенную поддержку параллелизации тестов.  
**Обоснование:**

- Ключевое слово parallel
- Sharding тестов
- Matrix builds
- Параллельные unit / integration / e2e тесты
- Существенное сокращение времени тестирования
- Быстрая обратная связь

---

## Дополнительные преимущества GitLab

### Встроенный Container Registry

- Не нужно подключать отдельный Docker Hub или AWS ECR
- Автоматическая интеграция с CI/CD
- Права доступа наследуются от репозитория
- Хранение образов рядом с кодом

### Управление окружениями

- Отслеживание окружений
- История деплоев
- Визуализация pipeline

### Автоматическое тестирование Merge Requests

- Pipeline для каждого MR
- Блокировка слияния при ошибках
- Контроль качества кода

### Встроенные инструменты безопасности

- SAST
- Dependency Scanning
- Container Scanning
- Secret Detection

### Интеграция с Kubernetes

- Подключение к K8s
- GitOps деплой
- Мониторинг подов

---

## Почему GitLab, а не альтернативы?

### Сравнение с GitHub Actions

- Более щедрый бесплатный tier
- Встроенный Container Registry
- Лучше для self-hosted сценариев

### Сравнение с Jenkins

- Не облачное решение
- Сложнее в поддержке
- Требует плагинов

### Сравнение с другими (CircleCI, TeamCity, Azure DevOps)

- Полное решение «всё в одном»
- Активное комьюнити
- Open source ядро
- Отличная поддержка Docker и Kubernetes

---

## Итоговое обоснование выбора GitLab

GitLab CI/CD выбран как оптимальное решение по следующим ключевым причинам:

1. Полное соответствие требованиям
2. Единая платформа
3. Идеально для микросервисов
4. Гибкость развёртывания
5. Баланс между простотой и мощностью
6. Активное развитие
7. Экономическая эффективность
8. Безопасность из коробки
9. Масштабируемость
10. Проверено индустрией

# Задание 2:

## Предлагаемое решение

Для обеспечения централизованного сбора и анализа логов в микросервисной архитектуре предлагаю использовать **ELK Stack** — проверенное enterprise-решение, состоящее из:

- **Elasticsearch** — распределённое хранилище и поисковая система для логов
- **Filebeat** — легковесный агент для сбора логов с хостов
- **Logstash** — инструмент для обработки и трансформации логов (опционально, для сложных сценариев)
- **Kibana** — веб-интерфейс для визуализации, поиска и анализа логов

---

## Обоснование выбора ELK Stack

ELK Stack выбран как оптимальное решение для крупной компании по следующим причинам:

### 1. Полное соответствие всем требованиям

Все 6 требований из задания полностью покрываются функциональностью ELK без необходимости в дополнительных системах.

### 2. Проверено масштабом

ELK используется крупнейшими технологическими компаниями мира для обработки петабайтов логов ежедневно.  
Netflix, LinkedIn, Uber, Microsoft — все используют Elasticsearch для логирования.

### 3. Мощь полнотекстового поиска

Для крупной компании с терабайтами логов критически важна скорость и точность поиска.  
Elasticsearch — лучший в индустрии поисковый движок, способный искать по миллиардам записей за миллисекунды.

### 4. Горизонтальная масштабируемость

Elasticsearch линейно масштабируется добавлением новых нод в кластер.  
Можно начать с 3 нод и вырасти до сотен без архитектурных изменений.

### 5. Enterprise-grade надёжность

- Встроенная репликация данных
- Automatic failover при сбоях нод
- Snapshot и restore для disaster recovery
- Проверенные patterns для высокой доступности

### 6. Богатая функциональность

Помимо базового логирования, ELK предоставляет алерты, ML для аномалий, security анализ, APM интеграцию — всё необходимое для comprehensive observability.

### 7. Активное развитие и поддержка

- Elastic выпускает новые версии каждые несколько месяцев
- Активное сообщество решает большинство проблем
- Коммерческая поддержка доступна для critical use cases
- Долгосрочная стабильность проекта гарантирована

### 8. Экосистема и интеграции

- Beats (Filebeat, Metricbeat, etc.) для различных источников данных
- Готовые модули для популярных приложений и систем
- Интеграции с Kubernetes, Docker, cloud providers
- Огромное количество плагинов от сообщества

### 9. Экономическая эффективность для enterprise

При больших объёмах self-hosted ELK значительно дешевле облачных альтернатив, при этом предоставляя больший контроль и гибкость.

### 10. Наличие экспертизы на рынке

ELK — один из самых популярных стеков в индустрии.  
Легко найти специалистов для поддержки, много обучающих материалов, большое сообщество для решения проблем.

### 11. Compliance и security

- Данные остаются в вашей инфраструктуре
- Полный контроль над доступом и шифрованием
- Audit logs для соответствия регуляторным требованиям
- Возможность развернуть в любом датацентре или облаке

### 12. Гибкость и расширяемость

- Open source core позволяет кастомизировать под специфичные нужды
- API для интеграции с любыми системами
- Можно постепенно добавлять новые возможности по мере роста

# Задание 3:

## Предлагаемое решение

Для обеспечения мониторинга хостов и сервисов в микросервисной архитектуре предлагаю использовать связку **Prometheus + Grafana**:

- **Prometheus** — система сбора, хранения и обработки метрик (time series database)
- **Grafana** — платформа для визуализации данных и создания дашбордов
- **Node Exporter** — агент для сбора системных метрик хостов
- **cAdvisor** — сбор метрик контейнеров
- **Application exporters** — специализированные экспортёры для различных сервисов
- **Alertmanager** — система управления алертами и уведомлениями

---

## Архитектура решения

### Уровень 1: Источники метрик

- Node Exporter на каждом хосте собирает системные метрики (CPU, RAM, Disk, Network)
- cAdvisor в Kubernetes собирает метрики контейнеров
- Приложения экспортируют свои бизнес-метрики через `/metrics` endpoint
- Специализированные экспортёры для инфраструктурных компонентов (PostgreSQL, Redis, Nginx)

### Уровень 2: Сбор и хранение

- Prometheus периодически опрашивает все источники метрик (pull-model)
- Service Discovery автоматически обнаруживает новые targets в Kubernetes
- Метрики сохраняются в локальной time series базе данных Prometheus
- Retention политики управляют хранением данных

### Уровень 3: Обработка и алертинг

- PromQL (язык запросов Prometheus) для агрегации и обработки метрик
- Recording rules для предварительного вычисления сложных метрик
- Alerting rules определяют условия для срабатывания алертов
- Alertmanager управляет уведомлениями (группировка, дедупликация, маршрутизация)

### Уровень 4: Визуализация

- Grafana подключается к Prometheus как data source
- Дашборды для разных уровней: инфраструктура, сервисы, бизнес-метрики
- Интерактивные графики с drill-down возможностями
- Templating для универсальных дашбордов

---

## Обоснование выбора Prometheus + Grafana

Prometheus + Grafana выбраны как оптимальное решение для крупной компании по следующим причинам:

### 1. Industry standard для cloud-native

De-facto стандарт для мониторинга Kubernetes и микросервисов. Используется CNCF (Cloud Native Computing Foundation) и крупнейшими tech компаниями.

### 2. Полное соответствие всем требованиям

Все 6 требований из задания покрываются функциональностью стека без костылей и дополнительных систем.

### 3. Архитектура для микросервисов

Pull-model и service discovery идеально подходят для динамических окружений, где сервисы постоянно создаются и удаляются.

### 4. Масштабируемость

Проверено компаниями с тысячами сервисов и миллионами time series. Можно начать с одного Prometheus и масштабировать через federation.

### 5. Богатая экосистема

Exporters для любых систем, готовые дашборды, большое сообщество. Не нужно изобретать велосипед.

### 6. Open source без vendor lock-in

Полный контроль, нет рисков зависимости от вендора, можно кастомизировать под любые нужды.

### 7. PromQL — мощный язык запросов

Позволяет делать сложные агрегации и анализ данных, необходимые для deep insights в работу системы.

### 8. Grafana — лучшая платформа визуализации

Intuitive UI, богатые возможности, активное развитие, огромное сообщество.

### 9. Экономическая эффективность

Бесплатно для любого масштаба. При объёмах крупной компании экономия составляет десятки/сотни тысяч долларов в год vs облачные альтернативы.

### 10. Наличие экспертизы

Prometheus + Grafana — самый популярный стек мониторинга. Легко найти специалистов, много обучающих материалов, активное сообщество для решения проблем.

---

## Интеграция с предыдущими решениями

### Synergy с ELK Stack (Задача 2)

- Grafana может показывать логи из Elasticsearch
- Корреляция метрик и логов на одном дашборде
- Переход от метрики к релевантным логам одним кликом
- Unified observability platform

### Synergy с GitLab CI/CD (Задача 1)

- Мониторинг CI/CD pipeline метрик
- Annotations на графиках при деплоях
- Связь между deployment events и изменениями метрик
- Быстрое выявление проблемных релизов

---

## Полная observability

Метрики (Prometheus) + Логи (ELK) + Traces (можно добавить Jaeger) = полная видимость системы.
